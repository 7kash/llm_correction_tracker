# LLM Mode - Choose which AI backend to use
# Options: 'mock', 'groq', 'huggingface', 'openai'
# RECOMMENDED: groq (free, fast, reliable!)
LLM_MODE=groq

# Groq Configuration (RECOMMENDED - FREE & FAST!)
# Get a FREE API key at: https://console.groq.com
# No credit card needed, generous free tier
GROQ_API_KEY=your_groq_api_key_here

# Groq Model (optional, defaults to llama-3.1-8b-instant)
# Available current models (as of 2024):
#   - llama-3.1-8b-instant (default, fast and smart)
#   - llama-3.1-70b-versatile (more powerful)
#   - mixtral-8x7b-32768 (very capable)
#   - gemma2-9b-it (Google's model)
GROQ_MODEL=llama-3.1-8b-instant

# Hugging Face Configuration (if LLM_MODE=huggingface)
# Get a FREE token at https://huggingface.co/settings/tokens
# Optional but recommended for unlimited API access (public API has rate limits)
HUGGING_FACE_TOKEN=

# Hugging Face Model (optional, defaults to Zephyr-7B-Beta)
# Popular free models that work without token:
#   - HuggingFaceH4/zephyr-7b-beta (default, excellent for Q&A, works with free API!)
#   - google/flan-t5-xxl (smaller, faster)
#   - mistralai/Mistral-7B-Instruct-v0.2 (requires token)
HUGGING_FACE_MODEL=HuggingFaceH4/zephyr-7b-beta

# OpenAI API Key (only needed if LLM_MODE=openai)
# Get from https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True
PORT=5000
